# 📌 End-to-End Tensor Operations in Deep Learning

## 🚀 Project Overview
This repository provides a deep dive into fundamental and advanced tensor operations using **both PyTorch and TensorFlow 2.0**. Mastering tensor operations is essential for deep learning, as tensors serve as the foundation for neural network computations. The project explores **tensor manipulations, einsum operations, broadcasting, matrix multiplications, and automatic differentiation**.


## 📌 Features
- 📌 **Basic tensor operations** (creation, reshaping, type casting, and indexing)
- 🔄 **Matrix multiplications and broadcasting**
- ✨ **Einops-powered tensor rearrangement** (PyTorch)
- 🧩 **Einsum operations for efficient computations**
- 🏗️ **Eigenvalues & Eigenvectors using `torch.linalg.eig()` & `tf.linalg.eigh()`**
- 🎨 **Tensor visualizations using Matplotlib**
- 🏋️ **Gradient computation with PyTorch Autograd & TensorFlow GradientTape**

## 🖥️ Notebooks
### 📌 TensorFlow 2.0
Explore TensorFlow-based tensor operations with a focus on `tf.einsum`, broadcasting, reshaping, and automatic differentiation.
📌 **Colab Notebook**: [TensorFlow Notebook](https://colab.research.google.com/drive/1cMXQrLLL3LUkPx-9aLsEVyuc_-C4W-IU?usp=sharing)

### 📌 PyTorch
Learn about tensor creation, transformations, matrix operations, and PyTorch-specific tensor operations like `einops`.
📌 **Colab Notebook**: [PyTorch Notebook](https://colab.research.google.com/drive/1As_pD71acXdz3X-OVQPhJT-G5wmZ1t9f?usp=sharing)


## 🏆 Key Takeaways
- Tensor operations are the core of deep learning models.
- **Einsum** optimizes computation for matrix operations.
- **Broadcasting** simplifies arithmetic across different tensor shapes.
- **Gradient computation** is seamless with PyTorch and TensorFlow.

## 🎥 Video Walkthrough
📌 Watch the video explanation here: [Video Link](https://youtu.be/7Iiv7WyhslY)

---
🚀 **Explore, experiment, and master deep learning tensors!**

